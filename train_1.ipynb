{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYdFggvwmwoBMVQQHUbCf9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shauryasawai/Medical_Research_Lab_Task/blob/main/train_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lBqecFg0hH-z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 1. DATASET CLASS\n",
        "# ============================================================================\n",
        "\n",
        "class FetalLandmarkDataset(Dataset):\n",
        "    \"\"\"Dataset for fetal ultrasound landmark detection\"\"\"\n",
        "\n",
        "    def __init__(self, csv_path, image_dir, img_size=256):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_path: Path to CSV with columns [image_name, ofd_1_x, ofd_1_y, ..., bpd_2_y]\n",
        "            image_dir: Directory containing ultrasound images\n",
        "            img_size: Target image size (default: 256x256)\n",
        "        \"\"\"\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.image_dir = image_dir\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # Store original image dimensions for denormalization\n",
        "        self.original_sizes = {}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        # Load image\n",
        "        img_name = row['image_name']\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if image is None:\n",
        "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
        "\n",
        "        # Store original size\n",
        "        orig_h, orig_w = image.shape\n",
        "        self.original_sizes[img_name] = (orig_w, orig_h)\n",
        "\n",
        "        # Resize image\n",
        "        image = cv2.resize(image, (self.img_size, self.img_size))\n",
        "\n",
        "        # Normalize image to [0, 1]\n",
        "        image = image.astype(np.float32) / 255.0\n",
        "\n",
        "        # Convert to tensor (1, H, W)\n",
        "        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        # Extract landmarks (8 values)\n",
        "        landmarks = row[1:9].values.astype(np.float32)\n",
        "\n",
        "        # Normalize coordinates to [0, 1]\n",
        "        # Assumes landmarks are given in original image coordinates\n",
        "        landmarks[0::2] = landmarks[0::2] / orig_w  # x coordinates\n",
        "        landmarks[1::2] = landmarks[1::2] / orig_h  # y coordinates\n",
        "\n",
        "        landmarks = torch.tensor(landmarks, dtype=torch.float32)\n",
        "\n",
        "        return image, landmarks, img_name"
      ],
      "metadata": {
        "id": "gVscQ-7RhRWG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 2. MODEL ARCHITECTURE\n",
        "# ============================================================================\n",
        "\n",
        "class LandmarkCNN(nn.Module):\n",
        "    \"\"\"CNN for landmark regression\"\"\"\n",
        "\n",
        "    def __init__(self, num_landmarks=8):\n",
        "        super(LandmarkCNN, self).__init__()\n",
        "\n",
        "        # Feature extraction layers\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),  # 256 -> 128\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),  # 128 -> 64\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),  # 64 -> 32\n",
        "\n",
        "            # Block 4\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),  # 32 -> 16\n",
        "        )\n",
        "\n",
        "        # Regression head\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 16 * 16, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_landmarks)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.regressor(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "UG51ayzIiYC7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 3. TRAINING UTILITIES\n",
        "# ============================================================================\n",
        "\n",
        "def calculate_pixel_error(pred, target, img_size=256):\n",
        "    \"\"\"\n",
        "    Calculate mean Euclidean distance error in pixels\n",
        "\n",
        "    Args:\n",
        "        pred: Predicted landmarks (normalized, 0-1)\n",
        "        target: Ground truth landmarks (normalized, 0-1)\n",
        "        img_size: Image size for denormalization\n",
        "\n",
        "    Returns:\n",
        "        Mean pixel error across all landmarks\n",
        "    \"\"\"\n",
        "    # Denormalize to pixel coordinates\n",
        "    pred_pixels = pred.cpu().numpy() * img_size\n",
        "    target_pixels = target.cpu().numpy() * img_size\n",
        "\n",
        "    # Reshape to (batch, num_points, 2)\n",
        "    pred_points = pred_pixels.reshape(-1, 4, 2)\n",
        "    target_points = target_pixels.reshape(-1, 4, 2)\n",
        "\n",
        "    # Calculate Euclidean distance for each point\n",
        "    distances = np.sqrt(np.sum((pred_points - target_points) ** 2, axis=2))\n",
        "\n",
        "    # Return mean distance\n",
        "    return distances.mean()\n",
        "\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_error = 0\n",
        "\n",
        "    pbar = tqdm(dataloader, desc=\"Training\")\n",
        "    for images, landmarks, _ in pbar:\n",
        "        images = images.to(device)\n",
        "        landmarks = landmarks.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, landmarks)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate metrics\n",
        "        total_loss += loss.item()\n",
        "        error = calculate_pixel_error(outputs.detach(), landmarks.detach())\n",
        "        total_error += error\n",
        "\n",
        "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'error': f'{error:.2f}px'})\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    avg_error = total_error / len(dataloader)\n",
        "\n",
        "    return avg_loss, avg_error\n",
        "\n",
        "\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    \"\"\"Validate the model\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_error = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, landmarks, _ in tqdm(dataloader, desc=\"Validating\"):\n",
        "            images = images.to(device)\n",
        "            landmarks = landmarks.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, landmarks)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            error = calculate_pixel_error(outputs, landmarks)\n",
        "            total_error += error\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    avg_error = total_error / len(dataloader)\n",
        "\n",
        "    return avg_loss, avg_error"
      ],
      "metadata": {
        "id": "i7FUNV_eihXa"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 4. MEASUREMENT UTILITIES\n",
        "# ============================================================================\n",
        "\n",
        "def calculate_measurements(landmarks, img_size=256):\n",
        "    \"\"\"\n",
        "    Calculate BPD and OFD from predicted landmarks\n",
        "\n",
        "    Args:\n",
        "        landmarks: Array of 8 values [ofd_1_x, ofd_1_y, ofd_2_x, ofd_2_y,\n",
        "                                       bpd_1_x, bpd_1_y, bpd_2_x, bpd_2_y]\n",
        "        img_size: Image size for denormalization\n",
        "\n",
        "    Returns:\n",
        "        (OFD, BPD) in pixels\n",
        "    \"\"\"\n",
        "    # Denormalize\n",
        "    landmarks_pixels = landmarks * img_size\n",
        "\n",
        "    # Extract points\n",
        "    ofd_1 = landmarks_pixels[0:2]\n",
        "    ofd_2 = landmarks_pixels[2:4]\n",
        "    bpd_1 = landmarks_pixels[4:6]\n",
        "    bpd_2 = landmarks_pixels[6:8]\n",
        "\n",
        "    # Calculate distances\n",
        "    OFD = np.linalg.norm(ofd_1 - ofd_2)\n",
        "    BPD = np.linalg.norm(bpd_1 - bpd_2)\n",
        "\n",
        "    return OFD, BPD\n",
        "\n",
        "\n",
        "def visualize_predictions(model, dataset, device, num_samples=4, save_path=None):\n",
        "    \"\"\"Visualize model predictions\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    fig, axes = plt.subplots(2, num_samples, figsize=(4*num_samples, 8))\n",
        "    if num_samples == 1:\n",
        "        axes = axes.reshape(-1, 1)\n",
        "\n",
        "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, idx in enumerate(indices):\n",
        "            image, gt_landmarks, img_name = dataset[idx]\n",
        "            image_input = image.unsqueeze(0).to(device)\n",
        "\n",
        "            # Predict\n",
        "            pred_landmarks = model(image_input).cpu().numpy()[0]\n",
        "            gt_landmarks = gt_landmarks.numpy()\n",
        "\n",
        "            # Denormalize\n",
        "            pred_pixels = pred_landmarks * 256\n",
        "            gt_pixels = gt_landmarks * 256\n",
        "\n",
        "            # Calculate measurements\n",
        "            pred_ofd, pred_bpd = calculate_measurements(pred_landmarks)\n",
        "            gt_ofd, gt_bpd = calculate_measurements(gt_landmarks.numpy())\n",
        "\n",
        "            # Plot\n",
        "            img_display = image.squeeze().numpy()\n",
        "\n",
        "            # Ground truth\n",
        "            axes[0, i].imshow(img_display, cmap='gray')\n",
        "            axes[0, i].plot([gt_pixels[0], gt_pixels[2]], [gt_pixels[1], gt_pixels[3]],\n",
        "                           'g-', linewidth=2, label='OFD')\n",
        "            axes[0, i].plot([gt_pixels[4], gt_pixels[6]], [gt_pixels[5], gt_pixels[7]],\n",
        "                           'b-', linewidth=2, label='BPD')\n",
        "            axes[0, i].scatter(gt_pixels[0::2], gt_pixels[1::2], c='red', s=50)\n",
        "            axes[0, i].set_title(f'Ground Truth\\nOFD: {gt_ofd:.1f}px, BPD: {gt_bpd:.1f}px')\n",
        "            axes[0, i].axis('off')\n",
        "            if i == 0:\n",
        "                axes[0, i].legend()\n",
        "\n",
        "            # Prediction\n",
        "            axes[1, i].imshow(img_display, cmap='gray')\n",
        "            axes[1, i].plot([pred_pixels[0], pred_pixels[2]], [pred_pixels[1], pred_pixels[3]],\n",
        "                           'g-', linewidth=2, label='OFD')\n",
        "            axes[1, i].plot([pred_pixels[4], pred_pixels[6]], [pred_pixels[5], pred_pixels[7]],\n",
        "                           'b-', linewidth=2, label='BPD')\n",
        "            axes[1, i].scatter(pred_pixels[0::2], pred_pixels[1::2], c='red', s=50)\n",
        "            axes[1, i].set_title(f'Prediction\\nOFD: {pred_ofd:.1f}px, BPD: {pred_bpd:.1f}px')\n",
        "            axes[1, i].axis('off')\n",
        "            if i == 0:\n",
        "                axes[1, i].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"‚úì Predictions saved to: {save_path}\")\n",
        "    else:\n",
        "        plt.savefig('predictions.png', dpi=150, bbox_inches='tight')\n",
        "        print(\"Visualization saved as 'predictions.png'\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "51CPSyFkiqlD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 5. FILE UPLOAD FOR GOOGLE COLAB\n",
        "# ============================================================================\n",
        "\n",
        "def upload_files_colab():\n",
        "    \"\"\"Upload CSV and images folder in Google Colab\"\"\"\n",
        "    from google.colab import files\n",
        "    import zipfile\n",
        "    import shutil\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"STEP 1: Upload CSV file\")\n",
        "    print(\"=\" * 60)\n",
        "    uploaded_csv = files.upload()\n",
        "    csv_filename = list(uploaded_csv.keys())[0]\n",
        "    print(f\"‚úì CSV uploaded: {csv_filename}\\n\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"STEP 2: Upload images folder as ZIP\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Please zip your images folder first, then upload the ZIP file\")\n",
        "    uploaded_zip = files.upload()\n",
        "    zip_filename = list(uploaded_zip.keys())[0]\n",
        "    print(f\"‚úì ZIP uploaded: {zip_filename}\\n\")\n",
        "\n",
        "    # Extract images\n",
        "    print(\"Extracting images...\")\n",
        "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall('.')\n",
        "\n",
        "    # Find the extracted folder\n",
        "    extracted_folders = [d for d in os.listdir('.') if os.path.isdir(d) and d != 'sample_data']\n",
        "    if extracted_folders:\n",
        "        image_dir = extracted_folders[0]\n",
        "    else:\n",
        "        image_dir = 'images'\n",
        "\n",
        "    print(f\"‚úì Images extracted to: {image_dir}\\n\")\n",
        "\n",
        "    # Count images\n",
        "    image_files = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    print(f\"Found {len(image_files)} images\")\n",
        "\n",
        "    return csv_filename, image_dir"
      ],
      "metadata": {
        "id": "ez_poVCXosgN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 6. MODEL CHECKPOINT MANAGER\n",
        "# ============================================================================\n",
        "\n",
        "class ModelCheckpointManager:\n",
        "    \"\"\"Manages model checkpoints for different experiments\"\"\"\n",
        "\n",
        "    def __init__(self, base_dir='experiments'):\n",
        "        self.base_dir = base_dir\n",
        "        os.makedirs(base_dir, exist_ok=True)\n",
        "        self.experiment_log = os.path.join(base_dir, 'experiment_log.csv')\n",
        "\n",
        "        # Initialize log if it doesn't exist\n",
        "        if not os.path.exists(self.experiment_log):\n",
        "            log_df = pd.DataFrame(columns=[\n",
        "                'experiment_id', 'timestamp', 'description', 'batch_size',\n",
        "                'learning_rate', 'num_epochs', 'img_size', 'best_val_error',\n",
        "                'best_epoch', 'total_params', 'model_path'\n",
        "            ])\n",
        "            log_df.to_csv(self.experiment_log, index=False)\n",
        "\n",
        "    def create_experiment(self, description=''):\n",
        "        \"\"\"Create a new experiment directory\"\"\"\n",
        "        timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
        "        exp_id = f\"exp_{timestamp}\"\n",
        "        exp_dir = os.path.join(self.base_dir, exp_id)\n",
        "        os.makedirs(exp_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"üìÅ Experiment Directory: {exp_dir}\")\n",
        "        print(f\"üìù Description: {description}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        return exp_id, exp_dir\n",
        "\n",
        "    def save_checkpoint(self, exp_dir, epoch, model, optimizer, scheduler,\n",
        "                       val_error, is_best=False):\n",
        "        \"\"\"Save model checkpoint\"\"\"\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'val_error': val_error,\n",
        "        }\n",
        "\n",
        "        # Save latest checkpoint\n",
        "        latest_path = os.path.join(exp_dir, 'checkpoint_latest.pth')\n",
        "        torch.save(checkpoint, latest_path)\n",
        "\n",
        "        # Save best checkpoint\n",
        "        if is_best:\n",
        "            best_path = os.path.join(exp_dir, 'checkpoint_best.pth')\n",
        "            torch.save(checkpoint, best_path)\n",
        "            return best_path\n",
        "\n",
        "        # Save epoch checkpoint (every 10 epochs)\n",
        "        if epoch % 10 == 0:\n",
        "            epoch_path = os.path.join(exp_dir, f'checkpoint_epoch_{epoch}.pth')\n",
        "            torch.save(checkpoint, epoch_path)\n",
        "\n",
        "        return latest_path\n",
        "\n",
        "    def save_config(self, exp_dir, config):\n",
        "        \"\"\"Save experiment configuration\"\"\"\n",
        "        import json\n",
        "        config_path = os.path.join(exp_dir, 'config.json')\n",
        "        with open(config_path, 'w') as f:\n",
        "            json.dump(config, f, indent=4)\n",
        "        print(f\"‚úì Configuration saved to: {config_path}\")\n",
        "\n",
        "    def save_history(self, exp_dir, history):\n",
        "        \"\"\"Save training history\"\"\"\n",
        "        history_path = os.path.join(exp_dir, 'training_history.csv')\n",
        "        history_df = pd.DataFrame(history)\n",
        "        history_df.to_csv(history_path, index=False)\n",
        "        print(f\"‚úì Training history saved to: {history_path}\")\n",
        "\n",
        "    def log_experiment(self, exp_id, config, best_val_error, best_epoch,\n",
        "                      total_params, model_path):\n",
        "        \"\"\"Log experiment results\"\"\"\n",
        "        log_df = pd.read_csv(self.experiment_log)\n",
        "\n",
        "        new_entry = {\n",
        "            'experiment_id': exp_id,\n",
        "            'timestamp': pd.Timestamp.now(),\n",
        "            'description': config.get('description', ''),\n",
        "            'batch_size': config['batch_size'],\n",
        "            'learning_rate': config['learning_rate'],\n",
        "            'num_epochs': config['num_epochs'],\n",
        "            'img_size': config['img_size'],\n",
        "            'best_val_error': best_val_error,\n",
        "            'best_epoch': best_epoch,\n",
        "            'total_params': total_params,\n",
        "            'model_path': model_path\n",
        "        }\n",
        "\n",
        "        log_df = pd.concat([log_df, pd.DataFrame([new_entry])], ignore_index=True)\n",
        "        log_df.to_csv(self.experiment_log, index=False)\n",
        "        print(f\"\\n‚úì Experiment logged to: {self.experiment_log}\")\n",
        "\n",
        "    def print_experiment_summary(self):\n",
        "        \"\"\"Print summary of all experiments\"\"\"\n",
        "        if os.path.exists(self.experiment_log):\n",
        "            log_df = pd.read_csv(self.experiment_log)\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"üìä EXPERIMENT SUMMARY\")\n",
        "            print(\"=\"*80)\n",
        "            print(log_df.to_string(index=False))\n",
        "            print(\"=\"*80 + \"\\n\")\n",
        "        else:\n",
        "            print(\"No experiments logged yet.\")\n",
        "\n",
        "    def load_best_model(self, exp_id, model):\n",
        "        \"\"\"Load the best model from an experiment\"\"\"\n",
        "        exp_dir = os.path.join(self.base_dir, exp_id)\n",
        "        best_path = os.path.join(exp_dir, 'checkpoint_best.pth')\n",
        "\n",
        "        if os.path.exists(best_path):\n",
        "            checkpoint = torch.load(best_path)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            print(f\"‚úì Loaded best model from: {best_path}\")\n",
        "            print(f\"  Epoch: {checkpoint['epoch']}, Val Error: {checkpoint['val_error']:.2f}px\")\n",
        "            return model\n",
        "        else:\n",
        "            print(f\"‚ùå Best model not found at: {best_path}\")\n",
        "            return None"
      ],
      "metadata": {
        "id": "p8AzOURBiuRD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 7. MAIN TRAINING SCRIPT\n",
        "# ============================================================================\n",
        "\n",
        "def main(use_colab_upload=True, experiment_description=''):\n",
        "    \"\"\"\n",
        "    Main training function\n",
        "\n",
        "    Args:\n",
        "        use_colab_upload: If True, will prompt for file upload in Colab.\n",
        "                         If False, uses hardcoded paths (for local execution)\n",
        "        experiment_description: Description of this experiment/hypothesis\n",
        "    \"\"\"\n",
        "    # Configuration\n",
        "    config = {\n",
        "        'batch_size': 16,\n",
        "        'num_epochs': 50,\n",
        "        'learning_rate': 1e-3,\n",
        "        'img_size': 256,\n",
        "        'train_split': 0.8,\n",
        "        'description': experiment_description\n",
        "    }\n",
        "\n",
        "    BATCH_SIZE = config['batch_size']\n",
        "    NUM_EPOCHS = config['num_epochs']\n",
        "    LEARNING_RATE = config['learning_rate']\n",
        "    IMG_SIZE = config['img_size']\n",
        "    TRAIN_SPLIT = config['train_split']\n",
        "\n",
        "    # Initialize checkpoint manager\n",
        "    checkpoint_manager = ModelCheckpointManager(base_dir='experiments')\n",
        "    exp_id, exp_dir = checkpoint_manager.create_experiment(experiment_description)\n",
        "\n",
        "    # Save configuration\n",
        "    checkpoint_manager.save_config(exp_dir, config)\n",
        "\n",
        "    CSV_PATH = \"role_challenge_dataset_ground_truth.csv\"\n",
        "    IMAGE_DIR = \"images\"\n",
        "\n",
        "    # Device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Load dataset\n",
        "    print(\"Loading dataset...\")\n",
        "    full_dataset = FetalLandmarkDataset(CSV_PATH, IMAGE_DIR, img_size=IMG_SIZE)\n",
        "\n",
        "    # Split dataset\n",
        "    train_size = int(TRAIN_SPLIT * len(full_dataset))\n",
        "    val_size = len(full_dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(\n",
        "        full_dataset, [train_size, val_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "\n",
        "    print(f\"Train samples: {train_size}, Validation samples: {val_size}\")\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
        "                           shuffle=False, num_workers=4)\n",
        "\n",
        "    # Create model\n",
        "    model = LandmarkCNN(num_landmarks=8).to(device)\n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5\n",
        "    )\n",
        "\n",
        "    # Get total parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    # Training loop\n",
        "    best_val_error = float('inf')\n",
        "    best_epoch = 0\n",
        "    history = {'epoch': [], 'train_loss': [], 'train_error': [],\n",
        "               'val_loss': [], 'val_error': [], 'learning_rate': []}\n",
        "\n",
        "    print(\"\\nStarting training...\")\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_error = train_epoch(model, train_loader, criterion,\n",
        "                                              optimizer, device)\n",
        "\n",
        "        # Validate\n",
        "        val_loss, val_error = validate(model, val_loader, criterion, device)\n",
        "\n",
        "        # Update scheduler\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Save history\n",
        "        history['epoch'].append(epoch + 1)\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_error'].append(train_error)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_error'].append(val_error)\n",
        "        history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Error: {train_error:.2f}px\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val Error: {val_error:.2f}px\")\n",
        "        print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        # Save checkpoint\n",
        "        is_best = val_error < best_val_error\n",
        "        checkpoint_path = checkpoint_manager.save_checkpoint(\n",
        "            exp_dir, epoch + 1, model, optimizer, scheduler,\n",
        "            val_error, is_best=is_best\n",
        "        )\n",
        "\n",
        "        if is_best:\n",
        "            best_val_error = val_error\n",
        "            best_epoch = epoch + 1\n",
        "            print(f\"‚úì New best model! Error: {val_error:.2f}px (saved to {checkpoint_path})\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training complete!\")\n",
        "    print(f\"Best validation error: {best_val_error:.2f}px at epoch {best_epoch}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Save training history\n",
        "    checkpoint_manager.save_history(exp_dir, history)\n",
        "\n",
        "    # Log experiment\n",
        "    best_model_path = os.path.join(exp_dir, 'checkpoint_best.pth')\n",
        "    checkpoint_manager.log_experiment(\n",
        "        exp_id, config, best_val_error, best_epoch,\n",
        "        total_params, best_model_path\n",
        "    )\n",
        "\n",
        "    # Plot training curves\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
        "\n",
        "    ax1, ax2, ax3 = axes\n",
        "\n",
        "    # Loss curves\n",
        "    ax1.plot(history['epoch'], history['train_loss'], label='Train', marker='o')\n",
        "    ax1.plot(history['epoch'], history['val_loss'], label='Validation', marker='s')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.set_title('Training and Validation Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Error curves\n",
        "    ax2.plot(history['epoch'], history['train_error'], label='Train', marker='o')\n",
        "    ax2.plot(history['epoch'], history['val_error'], label='Validation', marker='s')\n",
        "    ax2.axhline(y=best_val_error, color='r', linestyle='--',\n",
        "                label=f'Best: {best_val_error:.2f}px')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Error (pixels)')\n",
        "    ax2.set_title('Training and Validation Error')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    # Learning rate\n",
        "    ax3.plot(history['epoch'], history['learning_rate'], marker='o', color='green')\n",
        "    ax3.set_xlabel('Epoch')\n",
        "    ax3.set_ylabel('Learning Rate')\n",
        "    ax3.set_title('Learning Rate Schedule')\n",
        "    ax3.set_yscale('log')\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    curves_path = os.path.join(exp_dir, 'training_curves.png')\n",
        "    plt.savefig(curves_path, dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"‚úì Training curves saved to: {curves_path}\")\n",
        "\n",
        "    # Visualize predictions\n",
        "    print(\"\\nGenerating predictions visualization...\")\n",
        "    visualize_predictions(model, full_dataset, device, num_samples=4,\n",
        "                         save_path=os.path.join(exp_dir, 'predictions.png'))\n",
        "\n",
        "    # Print experiment summary\n",
        "    checkpoint_manager.print_experiment_summary()\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìÅ All results saved to: {exp_dir}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return exp_id, exp_dir, best_val_error\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Set to True for Google Colab (will prompt for file upload)\n",
        "    # Set to False for local execution (uses hardcoded paths)\n",
        "    RUNNING_IN_COLAB = True  # Change to False if running locally\n",
        "\n",
        "    # ========================================================================\n",
        "    # RUN MULTIPLE EXPERIMENTS (DIFFERENT HYPOTHESES)\n",
        "    # ========================================================================\n",
        "\n",
        "    # Experiment 1: Baseline\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üî¨ EXPERIMENT 1: Baseline Model\")\n",
        "    print(\"=\"*80)\n",
        "    exp1_id, exp1_dir, exp1_error = main(\n",
        "        use_colab_upload=RUNNING_IN_COLAB,\n",
        "        experiment_description=\"Baseline: LR=1e-3, BS=16, Epochs=50\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azfhRkW9q4fj",
        "outputId": "5c2bf4f3-a4f8-4655-961e-f6d7d3220785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üî¨ EXPERIMENT 1: Baseline Model\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "üìÅ Experiment Directory: experiments/exp_20251227_121436\n",
            "üìù Description: Baseline: LR=1e-3, BS=16, Epochs=50\n",
            "============================================================\n",
            "\n",
            "‚úì Configuration saved to: experiments/exp_20251227_121436/config.json\n",
            "\n",
            "============================================================\n",
            "Using device: cpu\n",
            "============================================================\n",
            "\n",
            "Loading dataset...\n",
            "Train samples: 497, Validation samples: 125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: 34,271,336\n",
            "\n",
            "Starting training...\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  22%|‚ñà‚ñà‚ñè       | 7/32 [01:28<05:20, 12.80s/it, loss=17.3975, error=1352.57px]"
          ]
        }
      ]
    }
  ]
}